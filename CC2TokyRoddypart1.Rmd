---
title: "CC2TokyRoddypart1"
output: github_document
---

```{r}
library(dada2); packageVersion("dada2")
```
```{r}
path <- "~/CC2TokyRoddypart1/seq"
list.files(path)
```
```{r}
fnFs <- sort(list.files(path, pattern="_1.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_2.fastq.gz", full.names = TRUE))
```

```{r}
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
```

```{r}
plotQualityProfile(fnFs[1:2])
```
```{r}
plotQualityProfile(fnRs[1:2])
```
#For the forward sequences we will trim the 20 last nucleotides (truncate the forward reads at position 260)
#For the Reverse sequences we will trim truncate at position 245

```{r}
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```

```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(260,245),
              maxN=0, maxEE=c(2 ,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=FALSE)
head(out)
```
```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread=TRUE)
```
```{r}
plotErrors(errF, nominalQ=TRUE)
```
```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
```
```{r}
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
```
```{r}
dadaFs[[1]]
```
```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers[[1]])
```
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```
```{r}
table(nchar(getSequences(seqtab)))
```
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
```
```{r}
sum(seqtab.nochim)/sum(seqtab)
```
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```
```{r}
taxa <- assignTaxonomy(seqtab.nochim, "~/CC2TokyRoddypart1/silva_nr99_v138.2_toSpecies_trainset.fa", multithread=TRUE)
```

```{r}
taxa.print <- taxa
rownames(taxa.print) <- NULL
head(taxa.print)
```
```{r}
library(phyloseq); packageVersion("phyloseq")
library(Biostrings); packageVersion("Biostrings")
library(ggplot2); packageVersion("ggplot2")
library(vegan)
theme_set(theme_bw())
```

```{r}
library(tidyverse)
library(phyloseq)
set.seed(81)
```
```{r}
#Recalibrer asv_ids
asv_ids <- paste0("ASV", seq_len(nrow(taxa)))
rownames(taxa) <- asv_ids
```

```{r}
if (length(asv_ids) == nrow(taxa)) {
  rownames(taxa) <- asv_ids
} else {
  stop("Dimension mismatch: Check the lengths of asv_ids and taxa!")
}
```

```{r}
# Comparer les ASV entre seqtab.nochim et taxa
asv_diff <- setdiff(rownames(seqtab.nochim), rownames(taxa))
print(asv_diff)
```
```{r}
# Exportation la table au format CSV
write.csv(seqtab.nochim, file = "asv_table.csv", quote=FALSE)
```

```{r}
# Exportez la table au format CSV
write.csv(taxa, file = "taxonomy.csv", quote = FALSE)
```

```{r}
# Table des ASV
asv_table <- read.csv(file="asv_table.csv", row.names = 1)
# Table de taxonomie
taxonomy <- read.csv(file="taxonomy.csv", row.names = 1)
# Métadonnées
metadata <- read.csv(file="Metatable.csv",sep=";",row.names=1)
```

```{r}
dim(asv_table)
dim(taxonomy)
dim(metadata)
```









